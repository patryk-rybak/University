Assignment 4

Your task will be to develop agents playing Connect4, trained on a dataset containing 20,000 games generated by a computer. The data has the following format:

    Each row describes a different game.
    Each row starts with the letter S (carrying no information).
    The game is presented as a sequence of moves (column numbers where tokens are dropped).
    At the end of each row, there is a letter indicating who won: A denotes the starting player, B denotes that the second player won, D indicates a draw.

Agents playing this game (without using neural networks) are located in the c4.py file. The competition.py file shows how to use them. Your task is to train neural networks that evaluate the game state as leading to the victory of the first or second player.

There is no starter code, but you can use any code from previous asignments, as well as competition.py, and c4.py files.
Problem 1 (6+1.5p)

Train a simple neural network that takes the game state as input and classifies it as winning for player A or winning for player B (assuming that if A wins the game, then all states of that game are winning for A). In this task, you should utilize Convolutional Neural Networks, encoding the game state similarly to AlphaGo (see Lecture Slides). Demonstrate the quality of the network by creating an agent that always selects the move that provides the best evaluated situation. The agent must decisively defeat a random agent.

You will receive 0.5 bonus points if your agent wins against the AgentMC(10) agent. You will receive another 1 bonus point if your agent wins against the AgentMinMaxMC(3,50) agent which was using to produce dataset.
Problem 2 (6+1.5p)

The content of this task is almost the same as the previous one. The only difference is that this time you should use the simplest possible neural network (not too large MLP), but you should pass to this network not the raw board, but features computed based on it (which you have to devise). An example feature: How many horizontal triplets of player A's tokens are there that can develop into a winning arrangement. Another feature: "Is it currently player A's turn?" There can be many features, do not hesitate to provide features that you are not sure about their usefulness. Demonstrate the quality of the network by creating an agent that always selects the move that provides the best evaluated situation. The agent must decisively defeat a random agent.

You will receive 0.5 bonus points if your agent wins against the AgentMC(10) agent. You will receive another 1 bonus point if your agent wins against the AgentMinMaxMC(3,50) agent which was using to produce dataset.
Problem 3. (optional, for interested individuals, 4p)

Choose the network from Problem 1 or 2. Teach it simultaneously to predict the value of a state as well as the best move in that state (policy). Propose an agent that utilizes both the policy and value function.

