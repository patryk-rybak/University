{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ulhVYI86xhZ"
   },
   "source": [
    "# Assignment 3\n",
    "\n",
    "**Submission deadlines:**\n",
    "- deadline: last lab session Tuesday, 09.04.2023\n",
    "\n",
    "**Points:** Aim to get 8 points + 2 extra\n",
    "\n",
    "## Submission instructions\n",
    "The class is held remotely. To submit your solutions please show the notebook over the video call. Make sure you know all the questions and answers, and that the notebook contains results (before presentation do `Runtime -> Restart and run all`)\n",
    "\n",
    "For the problem 2, we provide the starter code,\n",
    "however, you are not required to use it as long as you properly solve the tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yO6z3irYDq7i"
   },
   "source": [
    "# Problem 1: Classify the Oxford Flowers dataset (Weight & Biases) [6p]\n",
    "\n",
    "In this task, you will train a convolutional neural network to classify images of flowers from the [Oxford Flowers 102 dataset](https://www.robots.ox.ac.uk/~vgg/data/flowers/102/). The dataset consists of 102 flower categories, and each class has between 40 and 258 images. The images have large scale, pose, and light variations. In addition, there are categories that have large variations within the category and several very similar categories.\n",
    "\n",
    "    \n",
    "The dataset is available in `torchvision.datasets.Flowers102` class. You can use the following code to load the dataset:\n",
    "\n",
    "```python\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "dataset = torchvision.datasets.Flowers102(root='./data', download=True, transform=transforms.ToTensor())\n",
    "```\n",
    "\n",
    "In this task you should run several experiments to classify the images.\n",
    "In order to track the experiments, you can use the `Weight & Biases` library; see the [documentation](https://docs.wandb.ai/quickstart) for more details.\n",
    "\n",
    "Implement your code as a single Python script or a Jupyter notebook. Remember to log the experiment configuration, hyperparameters, and results (e.g., training loss, validation loss, accuracy and test loss, accuracy).\n",
    "For logging, you can use the `wandb.log` function to log the metrics and hyperparameters. You can also log the model architecture, training curves, and other relevant information.\n",
    "\n",
    "* 1.1 **[2p]**:\n",
    "    * Your task is to implement a convolutional neural network from scratch using PyTorch.\n",
    "    * Your CNN should consist of convolutional layers (Conv2D), pooling layers (MaxPooling2D), activation layers (e.g., ReLU), and fully connected layers (if needed).\n",
    "    * Train your CNN on a small part of the dataset (e.g., 10%, 25%, 50%, 75%, 100% of the original training set) while keeping the validation and test sets constant.\n",
    "\n",
    "* 1.2 **[1p]**:\n",
    "    * Input normalization: experiment with different input normalization techniques (e.g., mean subtraction, standardization) and analyze their impact on the model's performance.\n",
    "\n",
    "* 1.3 **[1p]**:\n",
    "    * Experiment with different hyperparameters such as learning rate, batch size, number of epochs, and optimizer choice (e.g., SGD, Adam).\n",
    "\n",
    "* 1.4 **[1p]**:\n",
    "    * Modify your CNN architecture to include batch normalization and dropout layers.\n",
    "\n",
    "* 1.5 **[1p]**:\n",
    "    * Implement data augmentation techniques such as random rotations, shifts, flips, and zooms on the training dataset.\n",
    "    * Train your CNN with augmented data and compare the performance with the baseline model trained on the original data.\n",
    "\n",
    "* 1.6 ***[2p extra points]***:\n",
    "    * Implement residual connections in your CNN architecture; see the [ResNet paper](https://arxiv.org/abs/1512.03385) for more details.\n",
    "    * Implement inception modules in your CNN architecture; see the [GoogLeNet paper](https://arxiv.org/abs/1409.4842) for more details.\n",
    "                \n",
    "\n",
    "Analyze the results obtained from different experiments.\n",
    "Discuss the effects of varying training set size, hyperparameters, batch normalization, dropout, and data augmentation on the CNN's performance.\n",
    "Provide insights into how these factors influence model training, convergence, and generalization.\n",
    "\n",
    "You can use the `Weight & Biases` reports to present your findings in a comprehensive report or presentation; see the [documentation](https://docs.wandb.ai/quickstart) for more details.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M19CXKMsi2Of"
   },
   "source": [
    "# Problem 2: Reusing a VGG Network [2p]\n",
    "\n",
    "Training large-scale models takes much time and resources. It also requires caution when picking hyperparameters. It is a common practice to share learned parameters of large models, and reuse them in different tasks. Weight matrices can be shared, even between entirely different frameworks. Further reading: [How transferable are features in deep neural networks?](https://arxiv.org/abs/1411.1792) by Yosinski et al.\n",
    "\n",
    "Neural networks trained for image classification might be seen as composed of two elements: a feature extractor, and a classifier. The former is typically made of a stack of convolutional layers, while the latter is the last linear layer of the model.\n",
    "\n",
    "We will focus on the deepest models - VGG16 and/or VGG19. To complete the task, load pre-trained VGG model. Then:\n",
    "1. **[1p]** Train the classifier part of the network on the\n",
    "  [Caltech101](http://www.vision.caltech.edu/Image_Datasets/Caltech101/) dataset of images:\n",
    "  * replace the classifier with a new randomly initialized one, whose output dimensionality matches\n",
    "    the number of classes of the Caltech101 dataset. You can replace all layers in the classifier\n",
    "    part of the VGG with just one affine projection into 102 classes.\n",
    "  * to significantly reduce training time and avoid destroying network weights early in the training,\n",
    "    train only the weights of the classifier. You can achieve this by applying the optimization only\n",
    "    to the classifier's parameters.\n",
    "    \n",
    "2. **[1p]** Assess the usefulness of using dropout and data augmentation during classifier training.\n",
    "  \n",
    "This procedure should quickly give you less than 10% training errors on the Caltech101 dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vaNF2mn2iwOJ"
   },
   "source": [
    "## Starter Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.Flowers102(root='./data', download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset Flowers102\n",
       "    Number of datapoints: 1020\n",
       "    Root location: ./data\n",
       "    split=train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lXZDHA5q6xjB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patryk/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/patryk/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace=True)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vgg = VGG(\"vgg19\")\n",
    "# if CUDA:\n",
    "#     vgg.cuda()\n",
    "\n",
    "vgg = models.vgg19(pretrained=False)\n",
    "if torch.cuda.is_available():\n",
    "    vgg.cuda()\n",
    "\n",
    "vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jebay0P96xjF",
    "outputId": "26ddf175-9c79-44e9-cb3c-26fbb0c88bbb"
   },
   "outputs": [],
   "source": [
    "# List layers in the model\n",
    "# print(\"Feature layers\")\n",
    "# print(\"--------------\")\n",
    "# for name, layer in zip(vgg.feature_names, vgg.features):\n",
    "#     print(\"{1: <12} {0: <8}  ({2}\".format(name, *str(layer).split(\"(\", 1)))\n",
    "# print(\"\\nClassifier layers\")\n",
    "# print(\"-----------------\")\n",
    "# for layer in vgg.classifier:\n",
    "#     print(\"{: <12}({}\".format(*str(layer).split(\"(\", 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UT6hkRWw6xjL"
   },
   "outputs": [],
   "source": [
    "class SubsampledImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, indexes, transform, **kwargs):\n",
    "        super(SubsampledImageDataset, self).__init__(**kwargs)\n",
    "        self.dataset = dataset\n",
    "        self.indexes = indexes\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        img, label = self.dataset[self.indexes[i]]\n",
    "        img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5jgFe5OXCcDf",
    "outputId": "2a48b1c2-140d-4c6d-bf45-8fc0eaea09d6"
   },
   "outputs": [],
   "source": [
    "#![ -d 101_ObjectCategories.tar.gz ] || gdown https://drive.google.com/u/0/uc?id=137RyRjvTBkBiIfeYBNZBtViDHQ6_Ewsp\n",
    "![ -e 101_ObjectCategories.tar.gz ] || gdown https://drive.google.com/u/0/uc?id=10NIeg2v6b9SzBBkqzbxUT_xTTgzIjsmv\n",
    "![ -d 101_ObjectCategories ] || tar zxf 101_ObjectCategories.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "OEjc18HS6xjP"
   },
   "outputs": [],
   "source": [
    "caltech_whole_dataset = torchvision.datasets.ImageFolder(\"./101_ObjectCategories/\")\n",
    "\n",
    "all_indexes = np.random.permutation(len(caltech_whole_dataset))\n",
    "train_size = int(len(all_indexes) * 0.8)\n",
    "\n",
    "caltech_train_dataset = SubsampledImageDataset(\n",
    "    caltech_whole_dataset,\n",
    "    all_indexes[:train_size],\n",
    "    torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.RandomResizedCrop(224),\n",
    "            torchvision.transforms.RandomHorizontalFlip(),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "caltech_train_dataset_10 = SubsampledImageDataset(\n",
    "    caltech_whole_dataset,\n",
    "    all_indexes[:int(train_size * 0.1)],\n",
    "    torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.RandomResizedCrop(224),\n",
    "            torchvision.transforms.RandomHorizontalFlip(),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "caltech_test_dataset = SubsampledImageDataset(\n",
    "    caltech_whole_dataset,\n",
    "    all_indexes[train_size:],\n",
    "    torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.Resize(256),\n",
    "            torchvision.transforms.CenterCrop(224),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "caltech_datasets = {\n",
    "    \"train\": caltech_train_dataset,\n",
    "    \"train_10\": caltech_train_dataset_10,\n",
    "    \"test\": caltech_test_dataset,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i58mkB6h6xjW",
    "outputId": "58da8aaf-02cc-4eb9-e869-bfc5b72e8501"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "caltech_loaders = {\n",
    "    \"train\": torch.utils.data.DataLoader(\n",
    "        caltech_datasets[\"train\"], batch_size=batch_size, num_workers=4, shuffle=True\n",
    "    ),\n",
    "    \"train_10\": torch.utils.data.DataLoader(\n",
    "        caltech_datasets[\"train_10\"], batch_size=batch_size, num_workers=4, shuffle=True\n",
    "    ),\n",
    "    \"test\": torch.utils.data.DataLoader(\n",
    "        caltech_datasets[\"test\"], batch_size=batch_size, num_workers=4, shuffle=False\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 630
    },
    "id": "zsoBcCX56xjc",
    "outputId": "efe98907-59c6-49db-fd7e-74adb6b321ec"
   },
   "outputs": [],
   "source": [
    "# train_batch = next(iter(caltech_loaders[\"train\"]))\n",
    "# common.plotting.plot_mat(to_np(train_batch[0])[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UcET5NVe6xjh",
    "outputId": "b2e3e319-d41e-47dc-d126-ef007b00cfdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifier layers\n",
      "-----------------\n",
      "Linear      (in_features=25088, out_features=4096, bias=True)\n",
      "ReLU        (inplace=True)\n",
      "Dropout     (p=0.5, inplace=False)\n",
      "Linear      (in_features=4096, out_features=4096, bias=True)\n",
      "ReLU        (inplace=True)\n",
      "Dropout     (p=0.5, inplace=False)\n",
      "Linear      (in_features=4096, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClassifier layers\")\n",
    "print(\"-----------------\")\n",
    "for layer in vgg.classifier:\n",
    "    print(\"{: <12}({}\".format(*str(layer).split(\"(\", 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_VTxNcKN6xjp"
   },
   "outputs": [],
   "source": [
    "# Train only the classifier!\n",
    "def compute_error_rate(model, data_loader, cuda=True):\n",
    "    model.eval()\n",
    "    num_errs = 0.0\n",
    "    num_examples = 0\n",
    "    for x, y in data_loader:\n",
    "        if cuda:\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model.forward(x)\n",
    "            _, predictions = outputs.max(dim=1)\n",
    "            num_errs += (predictions != y).sum().item()\n",
    "            num_examples += x.size(0)\n",
    "    return 100.0 * num_errs / num_examples\n",
    "\n",
    "\n",
    "def train(\n",
    "    model, data_loaders, optimizer, criterion, num_epochs=1, log_every=100, cuda=True\n",
    "):\n",
    "    if cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    iter_ = 0\n",
    "    epoch = 0\n",
    "    best_params = None\n",
    "    best_val_err = np.inf\n",
    "    history = {\"train_losses\": [], \"train_errs\": [], \"val_errs\": []}\n",
    "    print(\"Training the model!\")\n",
    "    print(\"You can interrupt it at any time.\")\n",
    "    try:\n",
    "        while epoch < num_epochs:\n",
    "            model.train()\n",
    "            # model.train_mode()\n",
    "            epoch += 1\n",
    "            for x, y in data_loaders[\"train_10\"]:\n",
    "                if cuda:\n",
    "                    x = x.cuda()\n",
    "                    y = y.cuda()\n",
    "                iter_ += 1\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                out = model.forward(x)\n",
    "                loss = criterion(out, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                _, predictions = out.max(dim=1)\n",
    "                err_rate = 100.0 * (predictions != y).sum() / out.size(0)\n",
    "\n",
    "                history[\"train_losses\"].append(loss.item())\n",
    "                history[\"train_errs\"].append(err_rate.item())\n",
    "\n",
    "\n",
    "                if iter_ % log_every == 0:\n",
    "                    print(\n",
    "                        \"Minibatch {0: >6}  | loss {1: >5.2f} | err rate {2: >5.2f}%\".format(\n",
    "                            iter_, loss.item(), err_rate\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "            val_err_rate = compute_error_rate(model, data_loaders[\"test\"], cuda)\n",
    "            history[\"val_errs\"].append((iter_, val_err_rate))\n",
    "\n",
    "            if val_err_rate < best_val_err:\n",
    "\n",
    "\n",
    "                best_epoch = epoch\n",
    "                best_val_err = val_err_rate\n",
    "\n",
    "\n",
    "            m = \"After epoch {0: >2} | valid err rate: {1: >5.2f}% | doing {2: >3} epochs\".format(\n",
    "                epoch, val_err_rate, num_epochs\n",
    "            )\n",
    "            print(\"{0}\\n{1}\\n{0}\".format(\"-\" * len(m), m))\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    if best_params is not None:\n",
    "        print(\"\\nLoading best params on validation set (epoch %d)\\n\" % (best_epoch))\n",
    "        model.parameters = best_params\n",
    "    plot_history(history)\n",
    "\n",
    "\n",
    "def plot_history(history):\n",
    "    figsize(16, 4)\n",
    "    subplot(1, 2, 1)\n",
    "    train_loss = np.array(history[\"train_losses\"])\n",
    "    semilogy(np.arange(train_loss.shape[0]), train_loss, label=\"batch train loss\")\n",
    "    legend()\n",
    "\n",
    "    subplot(1, 2, 2)\n",
    "    train_errs = np.array(history[\"train_errs\"])\n",
    "    plot(np.arange(train_errs.shape[0]), train_errs, label=\"batch train error rate\")\n",
    "    val_errs = np.array(history[\"val_errs\"])\n",
    "    plot(val_errs[:, 0], val_errs[:, 1], label=\"validation error rate\", color=\"r\")\n",
    "    ylim(0, 20)\n",
    "    legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fhtfR83r6xjv",
    "outputId": "30206697-5114-405d-cd7e-d2726720dde7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model!\n",
      "You can interrupt it at any time.\n",
      "----------------------------------------------------------\n",
      "After epoch  1 | valid err rate: 94.26% | doing  10 epochs\n",
      "----------------------------------------------------------\n",
      "----------------------------------------------------------\n",
      "After epoch  2 | valid err rate: 90.81% | doing  10 epochs\n",
      "----------------------------------------------------------\n",
      "----------------------------------------------------------\n",
      "After epoch  3 | valid err rate: 88.14% | doing  10 epochs\n",
      "----------------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'figsize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 31\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Train only the params of the classifier\u001b[39;00m\n\u001b[1;32m     26\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(vgg\u001b[38;5;241m.\u001b[39mclassifier\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvgg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaltech_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     33\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 81\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, data_loaders, optimizer, criterion, num_epochs, log_every, cuda)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mLoading best params on validation set (epoch \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (best_epoch))\n\u001b[1;32m     80\u001b[0m     model\u001b[38;5;241m.\u001b[39mparameters \u001b[38;5;241m=\u001b[39m best_params\n\u001b[0;32m---> 81\u001b[0m \u001b[43mplot_history\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 85\u001b[0m, in \u001b[0;36mplot_history\u001b[0;34m(history)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_history\u001b[39m(history):\n\u001b[0;32m---> 85\u001b[0m     \u001b[43mfigsize\u001b[49m(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     86\u001b[0m     subplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     87\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_losses\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'figsize' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO: implement a new classifier using `torch.nn.Sequential` and `torch.nn.Linear`\n",
    "classifier = nn.Sequential(\n",
    "    nn.Linear(in_features=25088, out_features=4096),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=4096, out_features=1000),\n",
    ")\n",
    "\n",
    "# Replace the classifier of our VGG network\n",
    "vgg.classifier = classifier\n",
    "\n",
    "# Disable gradient computation for the all parameter.\n",
    "# It will speed up the backward pass - the gradient will not be\n",
    "# backpropagated through the feature extractor.\n",
    "for p in vgg.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# Reenable gradient computation in our new classifier\n",
    "for p in vgg.classifier.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "criterion = (\n",
    "    nn.CrossEntropyLoss()\n",
    ")  # Note: nn.CrossEntropyLoss combines LogSoftmax with NLLLoss\n",
    "\n",
    "# Train only the params of the classifier\n",
    "optimizer = torch.optim.Adam(vgg.classifier.parameters(), lr=0.0001)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train(\n",
    "    vgg, caltech_loaders, optimizer, criterion, num_epochs=10, log_every=50, cuda=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Assignment3.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
